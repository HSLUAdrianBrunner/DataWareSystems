{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920ec42c",
   "metadata": {},
   "source": [
    "# Currency data API's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1c22f9",
   "metadata": {},
   "source": [
    "## Live Data extraction\n",
    "\n",
    "Lambda layer: group2_currency_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745bff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import date, datetime, timedelta\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b99a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "DB_CONFIG_DATALAKE = {\n",
    "    \"host\": os.getenv(\"var_host\"),\n",
    "    \"port\": os.getenv(\"var_port\"),\n",
    "    \"database\": os.getenv(\"var_database\"),\n",
    "    \"user\": os.getenv(\"var_user\"),\n",
    "    \"password\": os.getenv(\"var_password\")\n",
    "}\n",
    "\n",
    "DB_CONFIG_DWH = {\n",
    "    \"host\": os.getenv(\"var_host2\"),\n",
    "    \"port\": os.getenv(\"var_port\"),\n",
    "    \"database\": os.getenv(\"var_database2\"),\n",
    "    \"user\": os.getenv(\"var_user\"),\n",
    "    \"password\": os.getenv(\"var_password2\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fa9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_handler(event, context):\n",
    "    try:\n",
    "        # Setup date window (2 days ago)\n",
    "        trade_day = date.today() - timedelta(days=2)\n",
    "        print(f'trade_day: {trade_day}')\n",
    "        start_time = datetime.combine(trade_day, datetime.min.time())\n",
    "        print(f'start_time: {start_time}')\n",
    "        end_time = start_time + timedelta(days=1)\n",
    "        print(f'end_time: {end_time}')\n",
    "\n",
    "        # Connect to source and target databases\n",
    "        conn_src = psycopg2.connect(**DB_CONFIG_DATALAKE)\n",
    "        conn_tgt = psycopg2.connect(**DB_CONFIG_DWH)\n",
    "        cur_tgt = conn_tgt.cursor()\n",
    "\n",
    "        # Ensure fact_energy_trade table exists\n",
    "        cur_tgt.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS fact_energy_trade (\n",
    "            trade_id BIGINT PRIMARY KEY,\n",
    "            time_id INT,\n",
    "            location_id INT,\n",
    "            neighbor_country_id INT,\n",
    "            direction TEXT,\n",
    "            energy_value_gw FLOAT,\n",
    "            exchange_rate FLOAT,\n",
    "            value_chf FLOAT\n",
    "        );\n",
    "        \"\"\")\n",
    "        conn_tgt.commit()\n",
    "\n",
    "        # 1) Load and aggregate hourly energy CBET data\n",
    "        sql_energy = \"\"\"\n",
    "        SELECT\n",
    "        date_trunc('hour', timestamp) AS hour,\n",
    "        country,\n",
    "        SUM(value) AS energy_sum_gw\n",
    "        FROM tbl_energy_cbet_data\n",
    "        GROUP BY 1,2\n",
    "        ORDER BY 1,2;\n",
    "        \"\"\"\n",
    "        df_energy = pd.read_sql_query(sql_energy, conn_src)\n",
    "        # drop aggregate \"sum\" rows that arenâ€™t actual countries\n",
    "        df_energy = df_energy[df_energy['country'].str.strip().str.lower() != 'sum']\n",
    "\n",
    "        # 2) Load daily currency rates\n",
    "        sql_currency = \"\"\"\n",
    "        SELECT\n",
    "        DATE(timestamp) AS rate_date,\n",
    "        exchange_rate\n",
    "        FROM tbl_currency_data\n",
    "        WHERE source_currency='CHF' AND target_currency='EUR'\n",
    "        ;\n",
    "        \"\"\"\n",
    "        df_curr = pd.read_sql_query(sql_currency, conn_src)\n",
    "        # ensure one rate per day to avoid duplicate merges\n",
    "        df_curr = df_curr.drop_duplicates(subset=['rate_date'])\n",
    "\n",
    "        # 3) Prepare energy dataframe\n",
    "        df_energy['direction'] = df_energy['energy_sum_gw'].apply(\n",
    "            lambda x: 'import' if x>0 else ('export' if x<0 else 'none')\n",
    "        )\n",
    "        df_energy['energy_value_gw'] = df_energy['energy_sum_gw'].abs()\n",
    "        df_energy['rate_date'] = pd.to_datetime(df_energy['hour']).dt.date\n",
    "\n",
    "        # merge exchange rate\n",
    "        df_energy = df_energy.merge(\n",
    "            df_curr,\n",
    "            left_on='rate_date', right_on='rate_date',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # 4) Map foreign keys\n",
    "        # location_id always Switzerland = 6\n",
    "        df_energy['location_id'] = 6\n",
    "\n",
    "        # Fetch dim_countries for neighbor_country_id\n",
    "        sql_country = \"SELECT country_id, country_name_en FROM dim_countries;\"\n",
    "        df_country = pd.read_sql_query(sql_country, conn_tgt)\n",
    "        df_energy = df_energy.merge(\n",
    "            df_country,\n",
    "            left_on='country', right_on='country_name_en',\n",
    "            how='left'\n",
    "        )\n",
    "        df_energy.rename(columns={'country_id':'neighbor_country_id'}, inplace=True)\n",
    "\n",
    "        # Fetch dim_time for time_id\n",
    "        sql_time = \"SELECT time_id, timestamp_utc FROM dim_time;\"\n",
    "        df_time = pd.read_sql_query(sql_time, conn_tgt)\n",
    "        df_time['timestamp_utc'] = pd.to_datetime(df_time['timestamp_utc'])\n",
    "\n",
    "        df_energy = df_energy.merge(\n",
    "            df_time,\n",
    "            left_on='hour', right_on='timestamp_utc',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # 5) Lookup hourly energy prices and calculate value in EUR\n",
    "        sql_price = \"\"\"\n",
    "        SELECT\n",
    "        date_trunc('hour', timestamp) AS hour,\n",
    "        price\n",
    "        FROM tbl_energy_price_data;\n",
    "        \"\"\"\n",
    "        df_price = pd.read_sql_query(sql_price, conn_src)\n",
    "        # ensure one price per hour to avoid duplicate merges\n",
    "        df_price = df_price.drop_duplicates(subset=['hour'])\n",
    "        df_price['hour'] = pd.to_datetime(df_price['hour']).dt.floor('H')\n",
    "        df_price.rename(columns={'price':'price_eur_mwh'}, inplace=True)\n",
    "        \n",
    "\n",
    "        # merge hourly prices\n",
    "        df_energy = df_energy.merge(\n",
    "            df_price[['hour','price_eur_mwh']],\n",
    "            on='hour', how='left'\n",
    "        )\n",
    "\n",
    "        # calculate value in EUR: price (EUR/MWh) * 1000 * energy_value_gw / exchange_rate (CHF-EUR)\n",
    "        df_energy['value_chf'] = (df_energy['price_eur_mwh'] * 1000 * df_energy['energy_value_gw'] / df_energy['exchange_rate'])\n",
    "        df_energy['value_chf'] = df_energy['value_chf'].round(2)\n",
    "\n",
    "        # 6) Generate trade_id starting after current max\n",
    "        cur_tgt.execute(\"SELECT COALESCE(MAX(trade_id),0) FROM fact_energy_trade;\")\n",
    "        max_id = cur_tgt.fetchone()[0]\n",
    "        df_energy = df_energy.sort_values(['hour','neighbor_country_id'])\n",
    "        df_energy['trade_id'] = range(max_id+1, max_id+1+len(df_energy))\n",
    "\n",
    "        # 7) Build insert records\n",
    "        records = df_energy[['trade_id','time_id','location_id',\n",
    "                            'neighbor_country_id','direction',\n",
    "                            'energy_value_gw','exchange_rate','value_chf']].values.tolist()\n",
    "\n",
    "            # Batch insert (convert numpy types to native Python types)\n",
    "        insert_sql = (\"INSERT INTO fact_energy_trade \"\n",
    "            \"(trade_id, time_id, location_id, neighbor_country_id, direction, energy_value_gw, exchange_rate, value_chf) \"\n",
    "            \"VALUES %s\"\n",
    "        )\n",
    "        # Convert to list of tuples\n",
    "        records = df_energy[['trade_id','time_id','location_id',\n",
    "                            'neighbor_country_id','direction',\n",
    "                            'energy_value_gw','exchange_rate','value_chf']].values.tolist()\n",
    "        # Ensure each value is a Python scalar\n",
    "        clean_records = []\n",
    "        for row in records:\n",
    "            clean_row = []\n",
    "            for v in row:\n",
    "                # numpy types: use item(), else keep\n",
    "                clean_row.append(v.item() if hasattr(v, 'item') else v)\n",
    "            clean_records.append(tuple(clean_row))\n",
    "\n",
    "        execute_values(cur_tgt, insert_sql, clean_records)\n",
    "        conn_tgt.commit()\n",
    "\n",
    "        # Close connections\n",
    "        cur_tgt.close()\n",
    "        conn_src.close()\n",
    "        conn_tgt.close()\n",
    "\n",
    "        return { 'status':'success', 'rows_inserted': len(clean_records) }\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f'Error: {str(e)}')\n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
